
The objective of this enhancement is to integrate the recent developments of Grainne in regard to the aggregator classifier into the current framework

# As it works now

* Each individual classifier (`rta_process_simple.py`) generates the result of its prediction in the format of a JSON event published on a kafka topic
  * The Kafka topic is `iot_har_predict_aggr`
* The `har_predict_aggr_ensemble.py` listens to this topic `iot_har_predict_aggr` and collect periodically (given by the `spark.batch_duration` in `conf/rta.properties`) all the event generated by the different individual classifiers.
* The `har_predict_aggr_ensemble.py` uses a majority voting algorithm to select the final prediction and publishes this result to the `iot_har_novelty_detect` kafka topic
  * The majority-voting (`def simulated_prediction(list_events)`) algorithm is very simple. It outputs the value which is the most present into the set of data it collected.


# Enhancement
* Grainne Arrived to the conclusion that it's prefereable to use Naive Bayes model for making this final prediction based on individual classifiers.
* The idea here, is to enhance the  `har_predict_aggr_ensemble.py` such as it support this new model.

## Command Line enhancement

  * The current `har_predict_aggr_ensemble.py` usage is:
    ```
      har_predict_aggr_ensemble.py voting | randomForest
    ```
  * We propse to extend it to
    ```
      har_predict_aggr_ensemble.py voting | randomForest | naiveBayes
    ```

  * From a usage perspective we have:
    * A naive bayes based `har_predict_aggr_ensemble.py` won't be able to run with `rta_process_simple.py` started in `spark` mode.
    * Said differently
      * all `rta_process_simple.py` must run the same model type (`spark` or `sklearn`)
      * if all `rta_process_simple.py` are in a `spark` mode then the `har_predict_aggr_ensemble.py` will be in a `voting` or `randomForest` mode
      * if all `rta_process_simple.py` are in a `sklearn` mode then the `har_predict_aggr_ensemble.py` will be in a `naiveBayes` mode

## Code enhancement

* The HDFS model loading (line 177 to 189) should be executed only if the `algorithm_mode` is `randomForest`.
* A new test (in this space of 177-189) must be added based on the `algorithm_name`. It it is = to `naiveBayes` then Grainne model must be loaded.

* The `process_data()` function already support the `randomForest` & `voting` `algorithm_mode` (line 383 - 400).
* We must extend it to support the new `naiveBayes` mode.
  * In line 367 the `process_rt_data()` is invoked based on the `user_data_rdd` coming from the spark streaming module.
    * The `process_rt_data()` implements a buffer mechanism to retrieve the values that are submited to the model prediction (called `selected_data`)
    * At this stage a test must me done on the `algorithm_name`
      * if it is `voting` or `randomForest` then we use the existing `process_rt_data()`
      * if it is `naiveBayes` then we use a new function (called `process_rt_data_naiveBayes()`)
  * For `voting` or `randomForest` case the prediction is performed in the line 383 or 389 based on the output format `selected_data`
  * For `naiveBayes`, and simplify the code we propose to perform both the data concatenation **AND** prediction into the same `process_rt_data_naiveBayes()`
  * This means that we **we will not** add a new test in line 401 ike ` elif self.algorithm_name == VALID_ALGORITHM_LIST[2]:`
  * This mean that we will duplicate the code for sending the result to the kafka messaging bus (code from line 416 -- 446)

## process_rt_data_naiveBayes()
* This method get in input `user_data_rdd` and produce as a result the aggregated prediction.
* The result is produced directly on kafka and cassandra. This means that we duplicate the code from line 416 -- 446 to perform this operation
* The output format is given by the line 416
* The `activity` field contains the predicted value which is a **number** not a string.

### Input format
  * `self.process_rt_data_naiveBayes(user_data_rdd)`
  * `user_data_rdd` contains the JSON payload generated by the different processors.
  * An example of such event is given below

```
    {"eventId": "eadb9bb8-b9fd-4bfe-850d-bce3ceaf7189", "processor_name": "har_randomforest_accelerometer", "userid": "vincent.planat@hpe.com", "result": 3.0, "time_stamp": 1460995726187}
```
  * The `time_stamp` value should be aligned to the periodicity at which the `process_simple` processed the data.

### logic
* group the `user_data_rdd` by `user_id`. This is not done currently by Grainne's code
* For each user
    * Perform the data concataination similar to
    ```
      test = pandas.concat([df.set_index(['window', 'label']) for df in [accpred, gyrpred, barpred, altpred, distpred]],axis=1).reset_index()
    ```
    * perform the prediction based on naiveBayes
    * Generate the result to kafka output topic `iot_har_novelty_detect`
    * The format on this topic is given by the following code (line 416) where:
        * `eventId` will be generated by UUID4 library (as for the `process_simple()`)
        * `processor_name`: the `APP_NAME`, so `har_predict_aggr`
        * `user_id` the user id
        * `time_stamp` the time stamp of one of the events that have been concatenated
        * `activity` an value (0.0 to 3.0)


```
      predicted_result_record_4_kafka = {"eventId": xxxx],
                                         "processor_name": xxxx,
                                         "userid": xxxx,
                                         "time_stamp": xxxxx],
                                         "activity": xxxxxx}
```


## Notes
* The `USER_LIST` in line 28 of the `har_predict_aggr_ensemble.py` is deprecated. Should be commented. The list of users is taken from the list of available models
* The `VALID_ALGORITHM_LIST` will have to be extended by a `naiveBayes` value.
* The `VALID_ALGORITHM_LIST` must be part of the `rta_constants.py`
